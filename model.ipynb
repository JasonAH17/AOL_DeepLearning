{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helmet Detection - YOLOv8 Pipeline\n",
    "\n",
    "This notebook handles the entire pipeline:\n",
    "1. **Setup**: Imports and directory validation.\n",
    "2. **Dataset Preparation**: Converts VOC XML annotations to YOLO format, splits data into Train/Validation, and organizes folders.\n",
    "3. **Configuration**: Generates the `data.yaml` file required by YOLO.\n",
    "4. **Training**: Fine-tunes a YOLOv8 model on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Ensure reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "# Value from your previous setup\n",
    "PROJECT_ROOT = r\"C:\\Users\\jsnal\\OneDrive - Bina Nusantara\\Semester 3\\Deep Learning\\AOL Project\"\n",
    "SOURCE_DATASET = os.path.join(PROJECT_ROOT, \"dataset\")\n",
    "SOURCE_IMAGES = os.path.join(SOURCE_DATASET, \"images\")\n",
    "SOURCE_ANNOTATIONS = os.path.join(SOURCE_DATASET, \"annotations\")\n",
    "\n",
    "# Destination for prepared YOLO dataset\n",
    "DEST_DATASET = os.path.join(PROJECT_ROOT, \"datasets\", \"helmet_dataset\")\n",
    "TRAIN_IMAGES_DIR = os.path.join(DEST_DATASET, \"train\", \"images\")\n",
    "TRAIN_LABELS_DIR = os.path.join(DEST_DATASET, \"train\", \"labels\")\n",
    "VAL_IMAGES_DIR = os.path.join(DEST_DATASET, \"val\", \"images\")\n",
    "VAL_LABELS_DIR = os.path.join(DEST_DATASET, \"val\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_classes(annotations_dir):\n",
    "    \"\"\"Scans all XML files to find unique class names.\"\"\"\n",
    "    classes = set()\n",
    "    xml_files = [f for f in os.listdir(annotations_dir) if f.endswith('.xml')]\n",
    "    print(f\"Scanning {len(xml_files)} XML files for classes...\")\n",
    "    \n",
    "    for xml_file in tqdm(xml_files, desc=\"Scanning Classes\"):\n",
    "        try:\n",
    "            tree = ET.parse(os.path.join(annotations_dir, xml_file))\n",
    "            root = tree.getroot()\n",
    "            for obj in root.findall('object'):\n",
    "                name = obj.find('name').text\n",
    "                classes.add(name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {xml_file}: {e}\")\n",
    "    \n",
    "    return sorted(list(classes))\n",
    "\n",
    "def convert_box(size, box):\n",
    "    \"\"\"Converts min/max coordinates to YOLO norm x,y,w,h.\"\"\"\n",
    "    dw = 1. / size[0]\n",
    "    dh = 1. / size[1]\n",
    "    x = (box[0] + box[1]) / 2.0\n",
    "    y = (box[2] + box[3]) / 2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    return (x * dw, y * dh, w * dw, h * dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREPARE DATASET ---\n",
    "\n",
    "# 1. Find Classes\n",
    "classes = get_all_classes(SOURCE_ANNOTATIONS)\n",
    "print(f\"Detected Classes: {classes}\")\n",
    "\n",
    "# 2. Create Directories (Clean start)\n",
    "for d in [TRAIN_IMAGES_DIR, TRAIN_LABELS_DIR, VAL_IMAGES_DIR, VAL_LABELS_DIR]:\n",
    "    if os.path.exists(d):\n",
    "        shutil.rmtree(d)\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# 3. Split Data\n",
    "xml_files = [f for f in os.listdir(SOURCE_ANNOTATIONS) if f.endswith('.xml')]\n",
    "random.shuffle(xml_files)\n",
    "\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(xml_files) * split_ratio)\n",
    "train_files = xml_files[:split_index]\n",
    "val_files = xml_files[split_index:]\n",
    "\n",
    "print(f\"Total Files: {len(xml_files)}\")\n",
    "print(f\"Training Set: {len(train_files)} images\")\n",
    "print(f\"Validation Set: {len(val_files)} images\")\n",
    "\n",
    "def process_batch(files, img_dest, label_dest, batch_name=\"Processing\"):\n",
    "    for xml_file in tqdm(files, desc=batch_name):\n",
    "        try:\n",
    "            xml_path = os.path.join(SOURCE_ANNOTATIONS, xml_file)\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Image filename\n",
    "            filename = root.find('filename').text\n",
    "            src_img_path = os.path.join(SOURCE_IMAGES, filename)\n",
    "            \n",
    "            # Check if image exists, handle extension mismatches if needed\n",
    "            if not os.path.exists(src_img_path):\n",
    "                # Try common extensions\n",
    "                basename = os.path.splitext(xml_file)[0]\n",
    "                for ext in ['.jpg', '.png', '.jpeg', '.JPG']:\n",
    "                    if os.path.exists(os.path.join(SOURCE_IMAGES, basename + ext)):\n",
    "                        src_img_path = os.path.join(SOURCE_IMAGES, basename + ext)\n",
    "                        filename = basename + ext\n",
    "                        break\n",
    "                \n",
    "            if not os.path.exists(src_img_path):\n",
    "                print(f\"Skipping {xml_file}, image not found.\")\n",
    "                continue\n",
    "\n",
    "            # Image Size\n",
    "            size = root.find('size')\n",
    "            w = int(size.find('width').text)\n",
    "            h = int(size.find('height').text)\n",
    "\n",
    "            # Convert Labels\n",
    "            label_str = []\n",
    "            for obj in root.findall('object'):\n",
    "                cls_name = obj.find('name').text\n",
    "                if cls_name in classes:\n",
    "                    cls_id = classes.index(cls_name)\n",
    "                    xmlbox = obj.find('bndbox')\n",
    "                    b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), \n",
    "                         float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
    "                    bb = convert_box((w, h), b)\n",
    "                    label_str.append(f\"{cls_id} {bb[0]:.6f} {bb[1]:.6f} {bb[2]:.6f} {bb[3]:.6f}\")\n",
    "\n",
    "            # Save Labels to txt\n",
    "            txt_name = os.path.splitext(filename)[0] + \".txt\"\n",
    "            with open(os.path.join(label_dest, txt_name), 'w') as f:\n",
    "                f.write('\\n'.join(label_str))\n",
    "            \n",
    "            # Copy Image\n",
    "            shutil.copy(src_img_path, os.path.join(img_dest, filename))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {xml_file}: {e}\")\n",
    "\n",
    "process_batch(train_files, TRAIN_IMAGES_DIR, TRAIN_LABELS_DIR, \"Training Data\")\n",
    "process_batch(val_files, VAL_IMAGES_DIR, VAL_LABELS_DIR, \"Validation Data\")\n",
    "print(\"Dataset prepared successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GENERATE DATA.YAML ---\n",
    "yaml_content = {\n",
    "    'path': DEST_DATASET,\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'names': {i: name for i, name in enumerate(classes)}\n",
    "}\n",
    "\n",
    "yaml_path = os.path.join(PROJECT_ROOT, \"data.yaml\")\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(yaml_content, f, sort_keys=False)\n",
    "\n",
    "print(f\"Configuration saved to: {yaml_path}\")\n",
    "print(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- START TRAINING ---\n",
    "# Load a pretrained YOLOv8 nano model\n",
    "model = YOLO('yolov8n.pt') \n",
    "\n",
    "# Train the model\n",
    "# - data: path to our data.yaml\n",
    "# - epochs: number of training epochs (start with 50-100 for decent results)\n",
    "# - imgsz: image size (640 is standard)\n",
    "# - device: 0 for GPU, 'cpu' for CPU\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device='0',  # Use '0' if you have one GPU, or 'cpu'\n",
    "    project='helmet_detection_project',\n",
    "    name='yolov8n_run1'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloajagaksih (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
